{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import metrics for evaluation acuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular métricas\n",
    "def calcular_metricas(y_true, y_pred):\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraindo os dados separados de treino e teste\n",
    "\n",
    "x_train = pd.read_csv('data/x_train.csv')\n",
    "x_test = pd.read_csv('data/x_test.csv')\n",
    "Y_train = pd.read_csv('data/y_train.csv')\n",
    "Y_test = pd.read_csv('data/y_test.csv')\n",
    "\n",
    "Y_train = np.ravel(Y_train)\n",
    "Y_test = np.ravel(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizando a normalização dos dados\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Modelos avaliados\n",
    "\n",
    "- K-NN\n",
    "- Árvore de Decisão\n",
    "- Random Forest\n",
    "- XGBoost \n",
    "- LightGBM\n",
    "- MLP (Multilayer Perceptron)\n",
    "- SVM (Support Vector Machine)\n",
    "- LVQ (Learning Vector Quantization)\n",
    "- Comitê de Redes Neurais Artificiais\n",
    "- Comitê Heterogêneo (Stacking)\n",
    "\n",
    "Os modelos serão submetidos: \n",
    "- busca de hiperparamentos randomizada usando RandomizedSearchCV\n",
    "- Validação Cruzada de 10 folds\n",
    "- Métricas de avaliação acurácia, precisão, recall e F1-score (média e desvio padrão)\n",
    "- Matriz de Confusão\n",
    "- Curva de Aprendizado\n",
    "- Comparar as métricas de cada modelo usando Box Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros de modelos \n",
    "\n",
    "params_knn = {\n",
    "    'n_neighbors': range(1, 31),  \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "params_decision_tree = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': list(range(3, 21, 2)),\n",
    "    'min_samples_split': [2, 5, 10, 20],  # Mínimo de amostras para dividir um nó\n",
    "    'min_samples_leaf': [1, 2, 4, 8]  # Mínimo de amostras por folha\n",
    "}\n",
    "\n",
    "params_random_forest = {\n",
    "    'n_estimators': range(1, 200, 5),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(3, 30, 3)),\n",
    "}\n",
    "\n",
    "params_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3], # Grau do kernel polinomial\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]  # Controle de alcance do kernel\n",
    "}\n",
    "\n",
    "params_mlp = {\n",
    "    'hidden_layer_sizes': [(10,), (20,), (50,), (100,), (50, 50), (100, 50), (50, 25), (200, 100)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'max_iter': [200, 500]\n",
    "}\n",
    "\n",
    "params_xgboost = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],  \n",
    "    'max_depth': range(3, 11),\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 1] }\n",
    "\n",
    "params_lightgbm = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': range(3, 11),\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "models = {\n",
    "    'K-NN': (KNeighborsClassifier(), params_knn),\n",
    "    'Decision Tree': (DecisionTreeClassifier(random_state=42), params_decision_tree),\n",
    "    'Random Forest': (RandomForestClassifier(random_state=42), params_random_forest),\n",
    "    'SVM': (SVC(random_state=42), params_svm),\n",
    "    'MLP': (MLPClassifier(random_state=42), params_mlp),\n",
    "    'XGBoost': (XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), params_xgboost),\n",
    "    'LightGBM': (LGBMClassifier(random_state=42), params_lightgbm)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores hiperparâmetros para KNN:\n",
      "{'metric': 'manhattan', 'n_neighbors': 30, 'weights': 'distance'}\n",
      "Melhor score (acurácia média com CV=10): 0.5449\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "grid_search_knn = GridSearchCV(\n",
    "            estimator=knn,\n",
    "            param_grid=params_knn,\n",
    "            cv=10,  # Validação cruzada com 10 folds\n",
    "            n_jobs=-1  # Usa todos os processadores disponíveis\n",
    "        )\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "grid_search_knn.fit(x_train, Y_train)\n",
    "# Imprimindo os melhores parâmetros e o score\n",
    "print(f\"\\nMelhores hiperparâmetros para KNN:\")\n",
    "print(grid_search_knn.best_params_)\n",
    "print(f\"Melhor score (acurácia média com CV=10): {grid_search_knn.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores hiperparâmetros para Decision Tree:\n",
      "{'criterion': 'gini', 'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Melhor score (acurácia média com CV=10): 0.5714\n"
     ]
    }
   ],
   "source": [
    "decisiontree_grid = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid_search_decisiontree = GridSearchCV(\n",
    "    estimator=decisiontree_grid,\n",
    "    param_grid=params_decision_tree,\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_decisiontree.fit(x_train, Y_train)\n",
    "\n",
    "print(f\"\\nMelhores hiperparâmetros para Decision Tree:\")\n",
    "print(grid_search_decisiontree.best_params_)\n",
    "print(f\"Melhor score (acurácia média com CV=10): {grid_search_decisiontree.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores hiperparâmetros para KNN:\n",
      "{'splitter': 'best', 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_depth': 7, 'criterion': 'entropy'}\n",
      "Melhor score (acurácia média com CV=10): 0.5707\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(random_state=42)\n",
    "random_search_dt = GridSearchCV(\n",
    "    estimator=decisionTree,\n",
    "    param_distributions=params_decision_tree,\n",
    "    n_iter=10, \n",
    "    cv=10,  # Validação cruzada com 10 folds\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Usa todos os processadores disponíveis\n",
    ")\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "random_search_dt.fit(x_train, Y_train)\n",
    "# Imprimindo os melhores parâmetros e o score\n",
    "print(f\"\\nMelhores hiperparâmetros para KNN:\")\n",
    "print(random_search_dt.best_params_)\n",
    "print(f\"Melhor score (acurácia média com CV=10): {random_search_dt.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores hiperparâmetros para Random Forest:\n",
      "{'n_estimators': 191, 'max_depth': 15, 'criterion': 'gini'}\n",
      "Melhor score (acurácia média com CV=10): 0.5799\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "            estimator=rf,\n",
    "            param_distributions=params_random_forest,\n",
    "            n_iter=10, \n",
    "            cv=10,  # Validação cruzada com 10 folds\n",
    "            random_state=42,\n",
    "            n_jobs=-1  # Usa todos os processadores disponíveis\n",
    "        )\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "random_search_rf.fit(x_train, Y_train)\n",
    "# Imprimindo os melhores parâmetros e o score\n",
    "print(f\"\\nMelhores hiperparâmetros para Random Forest:\")\n",
    "print(random_search_rf.best_params_)\n",
    "print(f\"Melhor score (acurácia média com CV=10): {random_search_rf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m svm \u001b[38;5;241m=\u001b[39m \u001b[43mSVC\u001b[49m(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      2\u001b[0m random_search_svm \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m      3\u001b[0m             estimator\u001b[38;5;241m=\u001b[39msvm,\n\u001b[1;32m      4\u001b[0m             param_distributions\u001b[38;5;241m=\u001b[39mparams_svm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m             n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Usa todos os processadores disponíveis\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Treinando o modelo com os dados de treino\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "svm = SVC(random_state=42)\n",
    "random_search_svm = RandomizedSearchCV(\n",
    "            estimator=svm,\n",
    "            param_distributions=params_svm,\n",
    "            n_iter=10, \n",
    "            cv=10,  # Validação cruzada com 10 folds\n",
    "            random_state=42,\n",
    "            n_jobs=-1  # Usa todos os processadores disponíveis\n",
    "        )\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "random_search_svm.fit(x_train, Y_train)\n",
    "# Imprimindo os melhores parâmetros e o score\n",
    "print(f\"\\nMelhores hiperparâmetros para SVM:\")\n",
    "print(random_search_svm.best_params_)\n",
    "print(f\"Melhor score (acurácia média com CV=10): {random_search_svm.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=42)\n",
    "random_search_mlp = RandomizedSearchCV(\n",
    "            estimator=mlp,\n",
    "            param_distributions=params_mlp,\n",
    "            n_iter=10, \n",
    "            cv=10,  # Validação cruzada com 10 folds\n",
    "            random_state=42,\n",
    "            n_jobs=-1  # Usa todos os processadores disponíveis\n",
    "        )\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "random_search_mlp.fit(x_train, Y_train)\n",
    "# Imprimindo os melhores parâmetros e o score\n",
    "print(f\"\\nMelhores hiperparâmetros para MLP:\")\n",
    "print(random_search_mlp.best_params_)\n",
    "print(f\"Melhor score (acurácia média com CV=10): {random_search_mlp.best_score_:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
